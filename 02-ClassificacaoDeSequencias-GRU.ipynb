{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmai_ryJVhd5"
   },
   "source": [
    "# Classificando nomes com uma *Character-Level RNN*\n",
    "\n",
    "Esse notebook foi criado com base no tutorial do PyTorch: <br> \n",
    "https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goO_pZBdVzrf"
   },
   "source": [
    "### Problema: Dado um nome próprio de entrada, classificar esse nome de acordo com a nacionalidade a que ele pertence.\n",
    "\n",
    "Entrada: **Hinton**\n",
    "\n",
    "(-0.47) Scottish\n",
    "\n",
    "(-1.52) English\n",
    "\n",
    "(-3.57) Irish\n",
    "\n",
    "\n",
    "-\n",
    "\n",
    "Entrada: **Schmidhuber**\n",
    "\n",
    "(-0.19) German\n",
    "\n",
    "(-2.48) Czech\n",
    "\n",
    "(-2.68) Dutch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lliVTIikWKQf"
   },
   "source": [
    "### Import de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4689,
     "status": "ok",
     "timestamp": 1605621847492,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "Y2lbiDXXUNGM"
   },
   "outputs": [],
   "source": [
    "# Importa utilitários para normalização/remoção de acentos e manipulação de caracteres Unicode.\n",
    "import unicodedata\n",
    "\n",
    "# Importa constantes e funções úteis para strings (pontuação, etc.).\n",
    "import string\n",
    "\n",
    "# Importa módulos de sistema, gerador aleatório e utilidades do sistema operacional.\n",
    "import sys, random, os\n",
    "\n",
    "\n",
    "# Importa o PyTorch para tensores e modelos.\n",
    "import torch\n",
    "\n",
    "# Do PyTorch, traz o submódulo nn (camadas, losses, etc.).\n",
    "from torch import nn\n",
    "\n",
    "# Importa o NumPy para operações numéricas com arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Importa o Seaborn para melhorar a estética dos gráficos.\n",
    "import seaborn as sns\n",
    "\n",
    "# Define o estilo visual padrão dos gráficos do Seaborn.\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Importa o Matplotlib para plotagem.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Jupyter) Faz com que os gráficos sejam renderizados inline nas células.\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1605621850429,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "iIvPHo3Or62y"
   },
   "outputs": [],
   "source": [
    "# Cria um dicionário para hiperparâmetros e configs de treino/inferência.\n",
    "args = {\n",
    "# Taxa de aprendizado (learning rate) — aqui, 5×10⁻⁵.\n",
    "    'lr': 5e-5,\n",
    "# Fator de regularização L2 (weight decay) para evitar overfitting.\n",
    "    'regularizacao': 1e-7,\n",
    "# Número total de épocas de treinamento.\n",
    "    'num_epocas': 40,\n",
    "# Fecha o dicionário.\n",
    "}\n",
    "\n",
    "# (Opcional) Seleção automática do dispositivo: CUDA se disponível, senão CPU.\n",
    "# args['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Força o uso de CPU explicitamente (string 'cpu' também é aceita por torch.Tensor.to()).\n",
    "args['device'] = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVssEJvAiaHp"
   },
   "source": [
    "## Dados de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjtvooS3WsIB"
   },
   "source": [
    "### Importando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1605621868336,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "Smrb3GKqWsVu",
    "outputId": "ff368598-e30a-4194-9e97-f1d085b30acd"
   },
   "outputs": [],
   "source": [
    "# comente as duas linhas seguintes caso rode mais de uma vez\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip #\n",
    "# !unzip data.zip #\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1605621870665,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "xBgek-v83EA6",
    "outputId": "51268e25-0a73-4ede-a0af-452f76e7def5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Arabic.txt', 2000), ('Chinese.txt', 268), ('Czech.txt', 519), ('Dutch.txt', 297), ('English.txt', 3668), ('French.txt', 277), ('German.txt', 724), ('Greek.txt', 203), ('Irish.txt', 232), ('Italian.txt', 709), ('Japanese.txt', 991), ('Korean.txt', 94), ('Polish.txt', 139), ('Portuguese.txt', 74), ('Russian.txt', 9408), ('Scottish.txt', 100), ('Spanish.txt', 298), ('Vietnamese.txt', 73)]\n",
      "Minimo amostras ('Vietnamese.txt', 73) \n",
      "\n",
      "[b'Abreu', b'Albuquerque', b'Almeida', b'Alves', b'Araujo', b'Araullo', b'Barros', b'Basurto', b'Belo', b'Cabral']\n",
      "['Portuguese' 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese'\n",
      " 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese' 'Portuguese']\n"
     ]
    }
   ],
   "source": [
    "# Define uma função que lê um arquivo de nomes e retorna listas de nomes e rótulos.\n",
    "# Transforma um arquivo de nomes em listas e/ou arrays (nomes, rotulos)\n",
    "def readLines(filename):\n",
    "    # Lê o arquivo inteiro, remove espaços em branco nas extremidades e separa por quebras de linha.\n",
    "    lines     = open(filename).read().strip().split('\\n')\n",
    "    # Normaliza Unicode para ASCII (remove acentos); ATENÇÃO: o resultado aqui vira bytes (b'...').\n",
    "    nomes     = [unicodedata.normalize('NFKD', line).encode('ascii', 'ignore') for line in lines]\n",
    "    # Extrai a categoria a partir do nome do arquivo (ex.: 'Portuguese' de '.../Portuguese.txt').\n",
    "    categoria = filename.split('/')[-1].split('.')[0]\n",
    "    # Cria um vetor de rótulos repetindo a categoria para cada nome do arquivo.\n",
    "    rotulos   = np.repeat( categoria, len(nomes) )\n",
    "\n",
    "    # Retorna a lista de nomes normalizados e seus rótulos correspondentes.\n",
    "    return nomes, rotulos \n",
    "\n",
    "\n",
    "# Define o diretório onde estão os arquivos de nomes por idioma/categoria.\n",
    "root_path = 'data/names/'\n",
    "# Lista todos os arquivos do diretório, em ordem alfabética.\n",
    "arquivos = sorted(os.listdir(root_path))\n",
    "# Obtém a lista de categorias removendo a extensão '.txt' de cada arquivo.\n",
    "categorias = [a[:-4] for a in arquivos]\n",
    "\n",
    "# Inicializa contêineres para dados (nomes), rótulos e estatísticas por classe.\n",
    "dados, rotulos = [], []\n",
    "samples_perclass = []\n",
    "\n",
    "# Itera por cada arquivo de nomes disponível.\n",
    "for file_name in arquivos:\n",
    "  # Lê nomes e rótulos do arquivo atual.\n",
    "  retorno = readLines(os.path.join(root_path,file_name))\n",
    "  # Empilha a lista de nomes (bytes) na lista global 'dados'.\n",
    "  dados.append(retorno[0])\n",
    "  # Empilha o vetor de rótulos correspondente na lista global 'rotulos'.\n",
    "  rotulos.append(retorno[1])\n",
    "\n",
    "  # Armazena uma tupla (nome_do_arquivo, quantidade_de_nomes) para análise posterior.\n",
    "  samples_perclass.append( (file_name, len(retorno[0])) )\n",
    "\n",
    "\n",
    "# Imprime a contagem de amostras por arquivo/categoria.\n",
    "print(samples_perclass, )\n",
    "# Imprime qual categoria tem o menor número de amostras.\n",
    "print('Minimo amostras', min(samples_perclass, key= lambda k: k[1]), '\\n' )\n",
    "\n",
    "# Mostra os 10 primeiros nomes (em bytes) da categoria 'Portuguese'.\n",
    "print(dados[categorias.index('Portuguese')][0:10])\n",
    "# Mostra os 10 rótulos correspondentes a esses nomes.\n",
    "print(rotulos[categorias.index('Portuguese')][0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HlMtAzxfneB"
   },
   "source": [
    "### Convertendo os dados para tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMoQMcoRkSZd"
   },
   "source": [
    "**Convertendo os rótulos para tensor**\n",
    "\n",
    "Representação One-Hot de 18 categorias de idiomas que queremos prever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1605621873268,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "7HVlWioYjlUA",
    "outputId": "8d9d9345-b341-4485-b8b1-94c90ffcfa27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> Arabic tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# Define uma função que converte um vetor de rótulos (strings) para um tensor de índices inteiros (shape N×1).\n",
    "def label2tensor(rotulos):\n",
    "  # Cria um tensor de zeros com N linhas e 1 coluna (tipo inteiro 64 bits) para armazenar os índices das classes.\n",
    "  rotulos_tns = torch.zeros( len(rotulos), 1, dtype=torch.int64 )\n",
    "  # Percorre cada rótulo e sua posição k.\n",
    "  for k, rotulo in enumerate(rotulos):\n",
    "    # Encontra o índice da classe na lista global 'categorias' (ex.: 'Portuguese' → índice correspondente).\n",
    "    idx = categorias.index(rotulo)\n",
    "    # Grava o índice encontrado na linha k (coluna 0) do tensor de rótulos.\n",
    "    rotulos_tns[k][0] = idx\n",
    "  # Retorna o tensor N×1 com os índices das classes.\n",
    "  return rotulos_tns\n",
    "\n",
    "# Seleciona o vetor de rótulos da primeira categoria listada (por exemplo, 'Arabic'), conforme a ordem em 'arquivos'.\n",
    "rotulos_arabe = rotulos[0]\n",
    "# Converte esse vetor de rótulos de strings para um tensor de índices inteiros.\n",
    "rotulos_tns = label2tensor(rotulos_arabe)\n",
    "# Imprime o tipo do tensor resultante, o primeiro rótulo original e o índice correspondente no tensor.\n",
    "print(type(rotulos_tns), rotulos_arabe[0], rotulos_tns[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JCS8K8XkWNQ"
   },
   "source": [
    "**Convertendo os nomes para tensor**\n",
    "\n",
    "Aqui também usaremos a representação One-Hot, porém teremos que trabalhar com uma lista de tensores, pois os nomes tem comprimentos diferentes. Mais à frente no curso aprenderemos a lidar com isso da forma certa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1605621874458,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "ix07lvp9fmZi",
    "outputId": "0c745082-5590-407d-e6f8-82df615d018b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ '-\n",
      "K \n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])\n"
     ]
    }
   ],
   "source": [
    "# Define os caracteres válidos (apenas letras ASCII minúsculas e maiúsculas).\n",
    "caracteres_validos = string.ascii_letters + \" '-\"\n",
    "\n",
    "# Mostra o conjunto de caracteres válido (útil para checagem).\n",
    "print(caracteres_validos)\n",
    "\n",
    "# Tamanho do “vocabulário” de caracteres (número de colunas do one-hot).\n",
    "tam_dicionario = len(caracteres_validos)\n",
    "\n",
    "# Converte um nome (em bytes) para uma matriz one-hot de shape (len(nome), tam_dicionario).\n",
    "def nome2tensor(nome):\n",
    "    # Decodifica de bytes para string UTF-8 (ex.: b'José' → 'José').\n",
    "    nome = nome.decode('utf-8')\n",
    "    # Inicializa o tensor de zeros (uma linha por caractere, uma coluna por símbolo do vocabulário).\n",
    "    tns = torch.zeros(len(nome), tam_dicionario, dtype=torch.float32)\n",
    "    # Percorre cada caractere do nome e sua posição k.\n",
    "    for k, letra in enumerate(nome):\n",
    "        # Busca o índice da letra no vocabulário; se não existir, retorna -1.\n",
    "        idx = caracteres_validos.find(letra)\n",
    "        # Só marca 1.0 se a letra for conhecida (idx >= 0); evita escrever na coluna -1 por engano.\n",
    "        if idx >= 0:                 # << evita o índice -1\n",
    "            tns[k, idx] = 1.0\n",
    "        # Caso contrário, mantém a linha toda zero (caractere ignorado).\n",
    "        # else: linha fica toda zero (caractere ignorado)\n",
    "    # Retorna a matriz one-hot correspondente ao nome.\n",
    "    return tns\n",
    "\n",
    "# Seleciona a lista de nomes da primeira categoria (ex.: 'Arabic'), conforme a ordem em `arquivos`.\n",
    "dados_arabe = dados[0]\n",
    "\n",
    "# Converte cada nome dessa lista para seu tensor one-hot correspondente.\n",
    "dados_tns = [nome2tensor(dado) for dado in dados_arabe]\n",
    "\n",
    "# Imprime o primeiro caractere (já decodificado) e o vetor one-hot da primeira posição do primeiro nome.\n",
    "print(dados_arabe[0].decode('utf-8')[0],'\\n', dados_tns[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU4QqWqgBqxc"
   },
   "source": [
    "**Amostrando batch balanceado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1605621876555,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "GYfkmF8q5mT4",
    "outputId": "85b82f75-c2bd-4d6e-bda2-04192bfad5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139 torch.Size([6, 55]) torch.Size([1139, 1])\n"
     ]
    }
   ],
   "source": [
    "# Define o nº de amostras por classe como o mínimo entre as categorias (balanceamento por downsampling).\n",
    "num_amostras = min(samples_perclass, key= lambda k: k[1])[1]\n",
    "\n",
    "# Função que amostra, para cada categoria, 'size' nomes e retorna tensores dos nomes e rótulos.\n",
    "def sample_batch(size=num_amostras):\n",
    "  # Acumuladores de nomes (bytes) e rótulos (strings) do mini-conjunto balanceado.\n",
    "  dados_batch, rotulos_batch = [], []\n",
    "  # Percorre cada categoria disponível.\n",
    "  for cat in categorias:\n",
    "    \n",
    "    # Recupera a lista de nomes da categoria atual.\n",
    "    amostras_cat = dados[categorias.index(cat)]\n",
    "    # Escolhe 'size' índices aleatórios dessa categoria (por padrão, com reposição; use replace=False para sem reposição).\n",
    "    idx = np.random.choice(range(len(amostras_cat)), size=size)\n",
    "\n",
    "    # Coleta os nomes correspondentes aos índices sorteados e acumula.\n",
    "    dados_batch.extend([ r for k, r in enumerate(dados[categorias.index(cat)]) if k in idx])\n",
    "    # Coleta os rótulos correspondentes aos mesmos índices e acumula.\n",
    "    rotulos_batch.extend([ r for k, r in enumerate(rotulos[categorias.index(cat)]) if k in idx])\n",
    "\n",
    "  # Converte cada nome (bytes) para tensor one-hot (len(nome) × tam_dicionario).\n",
    "  dados_tns = [nome2tensor(dado) for dado in dados_batch]\n",
    "  # Converte os rótulos (strings) para tensor de índices (N × 1).\n",
    "  return dados_tns, label2tensor(rotulos_batch)\n",
    "\n",
    "# Gera um lote balanceado (mesmo nº por classe) e imprime algumas informações.\n",
    "dados_batch, rotulos_batch = sample_batch()\n",
    "print(len(dados_batch), dados_batch[0].size(), rotulos_batch.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por fim, vamos separar dados de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a função utilitária para dividir dados em treino e teste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste (80/20) com semente fixa para reprodutibilidade.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    # Conjunto de entradas (lista de tensores one-hot por nome).\n",
    "    dados_tns,\n",
    "    # Conjunto de rótulos correspondentes (tensor N×1 com índices de classe).\n",
    "    rotulos_tns,\n",
    "    # Proporção destinada ao conjunto de teste: 20%.\n",
    "    test_size=0.2,\n",
    "    # Semente para tornar o split determinístico.\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnZL-mUXmMtA"
   },
   "source": [
    "## Modelo Recorrente\n",
    "\n",
    "* Implemente um modelo para classificação de nomes próprios (série de caracteres) usando apenas camadas *RNNCell*, *Linear* e ativação *LogSoftmax*\n",
    "* Cada entrada (caracter) possui dimensão (52): alfabeto maiúsculo e minúsculo\n",
    "* *Hidden size* possui dimensão (256): hiperparâmetro \n",
    "* Saída possui dimensão (18): vetor de probabilidade de classes\n",
    "* Batch size = 1 **pra não termos que lidar com as sequências de tamanho variável.**\n",
    "\n",
    "### Links úteis\n",
    "\n",
    "RNNCell: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html#torch.nn.RNNCell\n",
    "\n",
    "Linear: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "\n",
    "Non-linear activations: https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1605622095577,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "PY9NvNN8kT-z"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 55, got 52",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m nome \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m52\u001b[39m)\u001b[38;5;241m.\u001b[39mto(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Executa uma passada de inferência para verificar o fluxo e as dimensões.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m saida \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnome\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, nome)\u001b[0m\n\u001b[1;32m     25\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtam_feature)\u001b[38;5;241m.\u001b[39mto(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Adiciona dimensão de batch (1) para casar com batch_first=True → (1, T, C).\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# nome.unsqueeze(0) - criando uma dimensão artificial para o batch = 1\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m saida, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Seleciona apenas a última saída temporal (estado do último caractere) com shape (1, tam_feature).\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(\"Saída da GRU:\", saida.size())\u001b[39;00m\n\u001b[1;32m     32\u001b[0m saida \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(saida[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m-> 1392\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1395\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1396\u001b[0m         hx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1404\u001b[0m     )\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:364\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n\u001b[1;32m    363\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m~/FCD/Alura/deep-learning-pytorch/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:315\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 55, got 52"
     ]
    }
   ],
   "source": [
    "# Define uma rede recorrente para classificar nomes em categorias usando GRU.\n",
    "class RNN(nn.Module):\n",
    "    # Construtor: recebe tamanhos de entrada (one-hot), oculto (features) e saída (nº de classes).\n",
    "    def __init__(self, tam_entrada, tam_feature, tam_saida):\n",
    "        # Inicializa a superclasse nn.Module.\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # Guarda os hiperparâmetros como atributos do módulo.\n",
    "        self.tam_entrada = tam_entrada\n",
    "        self.tam_feature = tam_feature\n",
    "        self.tam_saida   = tam_saida\n",
    "        \n",
    "        # Célula recorrente GRU processando sequências com batch_first=True → entrada (B, T, C).\n",
    "        self.rnn    = nn.GRU(self.tam_entrada, self.tam_feature, batch_first=True)\n",
    "        # Camada linear mapeando o estado oculto final para logits de classes.\n",
    "        self.linear = nn.Linear(self.tam_feature, self.tam_saida)\n",
    "        # Converte logits em log-probabilidades por classe (última dimensão).\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "    \n",
    "    # Define o fluxo direto: recebe um tensor (T, C) de um nome em one-hot.\n",
    "    def forward(self, nome):\n",
    "      \n",
    "        # Cria o estado oculto inicial da GRU com zeros: (num_layers, batch, hidden_size) = (1, 1, tam_feature).\n",
    "        batch_size = 1\n",
    "        hidden = torch.zeros(1, batch_size, self.tam_feature).to(args['device'])\n",
    "        \n",
    "        # Adiciona dimensão de batch (1) para casar com batch_first=True → (1, T, C).\n",
    "        # nome.unsqueeze(0) - criando uma dimensão artificial para o batch = 1\n",
    "        saida, hidden = self.rnn(nome.unsqueeze(0), hidden)\n",
    "        # Seleciona apenas a última saída temporal (estado do último caractere) com shape (1, tam_feature).\n",
    "        # print(\"Saída da GRU:\", saida.size())\n",
    "        saida = self.linear(saida[:, -1])\n",
    "        # Projeta para o espaço de classes → (1, tam_saida).\n",
    "        # print(\"Saída da Linear:\", saida.size())\n",
    "        saida = self.softmax(saida) \n",
    "        # Retorna log-probabilidades (1, tam_saida).\n",
    "        return saida\n",
    "\n",
    "# Define o tamanho do estado oculto da GRU (número de features internas).\n",
    "tam_feature = 256\n",
    "# Instancia o modelo com entrada = tamanho do dicionário, saída = número de categorias.\n",
    "model = RNN(tam_dicionario, tam_feature, len(categorias))\n",
    "# Move o modelo para o dispositivo definido em args['device'] (CPU/GPU).\n",
    "model.to(args['device'])\n",
    "\n",
    "# Cria um exemplo sintético: sequência de 8 caracteres, vocabulário de 52 (one-hot zero por enquanto).\n",
    "nome = torch.zeros(8, 55).to(args['device'])\n",
    "# Executa uma passada de inferência para verificar o fluxo e as dimensões.\n",
    "saida = model(nome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVSrUbUns5WH"
   },
   "source": [
    "## Loss e Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1605622099370,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "0UwVsprXr5BV"
   },
   "outputs": [],
   "source": [
    "# Define a função de perda NLL (compatível com saídas em log-probabilidade do LogSoftmax) e move para o device.\n",
    "criterion = nn.NLLLoss().to(args['device']) \n",
    "\n",
    "# Cria o otimizador Adam para os parâmetros do modelo, com taxa de aprendizado e regularização L2 definidas em args.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['regularizacao'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNex6BA1s4_W"
   },
   "source": [
    "## Treinamento\n",
    "\n",
    "A otimização é um processo que tem uma raíz muito bem definida de passo a passo, sempre fazemos:\n",
    "* Carregar os dados e colocar no dispositivo de hardware adequado\n",
    "* Forward do dado na rede\n",
    "* Cálculo da função de custo (no nosso caso uma função composta)\n",
    "* Passos de Otimização\n",
    "  * Zerar os gradientes do otimizador (`optimizer.zero_grad()`)\n",
    "  * Calcular os gradientes com base na loss (`loss.backward()`)\n",
    "  * Passo de otimização (`optimizer.step()`)\n",
    "\n",
    "Apesar de cada solução ter pequenas variações em um ou mais passos do fluxo, o esqueleto é sempre o mesmo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1605622106467,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "N3AvGhzMscZT"
   },
   "outputs": [],
   "source": [
    "# Define uma passada sobre os dados X/Y; alterna entre treino e avaliação conforme `etapa`.\n",
    "def forward(X, Y, etapa):\n",
    "\n",
    "  # Coloca o modelo em modo de treino (Dropout/BN em training) ou avaliação (eval).\n",
    "  if etapa == 'Treino': model.train()\n",
    "  else: model.eval()\n",
    "\n",
    "  # Inicializa acumuladores de acurácia e lista de perdas por amostra.\n",
    "  acuracia = 0.\n",
    "  loss_epoca = []\n",
    "\n",
    "  # Itera sincronicamente por amostra (dado) e rótulo (rotulo).\n",
    "  for k, (dado, rotulo) in enumerate(zip(X, Y)):\n",
    "      \n",
    "    # Move entrada e rótulo para o dispositivo configurado (CPU/GPU).\n",
    "    dado = dado.to(args['device'])\n",
    "    rotulo = rotulo.to(args['device'])\n",
    "    \n",
    "    # Forward: produz as pontuações/log-probabilidades do modelo.\n",
    "    saida = model(dado)\n",
    "    # Calcula a perda da amostra segundo o critério escolhido (ex.: NLLLoss).\n",
    "    loss = criterion(saida, rotulo)\n",
    "    # Armazena o valor escalar da perda (sem gradiente) para estatísticas.\n",
    "    loss_epoca.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    # Obtém a classe prevista (índice do maior valor na última dimensão).\n",
    "    _, pred = torch.max(saida, axis=-1)\n",
    "    # Soma 1 acerto se a predição coincide com o rótulo verdadeiro.\n",
    "    acuracia += 1 if pred[0].item() == rotulo[0].item() else 0\n",
    "\n",
    "    # Se estiver em etapa de treino, faz backprop e atualiza os pesos.\n",
    "    if etapa == 'Treino':\n",
    "      # Zera gradientes acumulados do passo anterior.\n",
    "      # Otimização\n",
    "      optimizer.zero_grad()\n",
    "      # Backpropaga o erro.\n",
    "      loss.backward()\n",
    "      # Aplica a atualização de parâmetros.\n",
    "      optimizer.step()\n",
    "\n",
    "  # Converte lista de perdas para NumPy e achata para facilitar estatísticas.\n",
    "  loss_epoca = np.asarray(loss_epoca).ravel()\n",
    "  # Converte acertos absolutos em fração de acertos (acurácia em [0,1]).\n",
    "  acuracia   = acuracia/float(len(loss_epoca))\n",
    "\n",
    "  # Cabeçalho de log amigável para diferenciar TREINO/TESTE.\n",
    "  print('\\n','*'*15 + etapa + '*'*15 )\n",
    "  # Exibe média±desvio da loss e acurácia; OBS: usa variável global `epoca`.\n",
    "  print('Epoca: {:}, Loss: {:.4f} +/- {:.4f}, Acurácia: {:.4f}'.format(epoca, loss_epoca.mean(), \n",
    "                                                                        loss_epoca.std(), \n",
    "                                                                        acuracia\n",
    "                                                                       )) \n",
    "  # Retorna a perda média da época e a acurácia correspondente.\n",
    "  return loss_epoca.mean(), acuracia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 673072,
     "status": "ok",
     "timestamp": 1605622782199,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "RaxYaVprzIS3",
    "outputId": "8d724eb0-2033-4539-ec83-bfbdff31c614"
   },
   "outputs": [],
   "source": [
    "# Inicializa listas para registrar a loss média por época (treino e teste).\n",
    "loss_treino, loss_test = [], []\n",
    "# Inicializa listas para registrar a acurácia por época (treino e teste).\n",
    "acc_treino, acc_test = [], []\n",
    "\n",
    "# Amostra um conjunto fixo e pequeno de teste para avaliação a cada época.\n",
    "dados_test, rotulos_test = sample_batch(size=5)\n",
    "# Loop principal de treinamento por 1000 épocas (pode ser demorado).\n",
    "for epoca in range(1000):\n",
    "\n",
    "  # Para cada época, amostra um lote balanceado de treinamento.\n",
    "  dados_tns, rotulos_tns = sample_batch()\n",
    "  # Executa a passada de TREINO: retorna loss média e acurácia da época.\n",
    "  loss, acuracia = forward(dados_tns, rotulos_tns, 'Treino')\n",
    "  # Armazena a loss de treino desta época.\n",
    "  loss_treino.append(loss)\n",
    "  # Armazena a acurácia de treino desta época.\n",
    "  acc_treino.append(acuracia)  \n",
    "\n",
    "  # Executa a passada de TESTE no conjunto fixo (sem atualização de pesos).\n",
    "  loss, acuracia = forward(dados_test, rotulos_test, 'Teste')\n",
    "  # Armazena a loss de teste desta época.\n",
    "  loss_test.append(loss)\n",
    "  # Armazena a acurácia de teste desta época.\n",
    "  acc_test.append(acuracia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-jhpXs_z7vb"
   },
   "source": [
    "## Análise de Convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "executionInfo": {
     "elapsed": 1575,
     "status": "ok",
     "timestamp": 1605623194267,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "gM4BTf7lz7Q6",
    "outputId": "3f463882-5397-46b5-e98c-694d97a2c35c"
   },
   "outputs": [],
   "source": [
    "# Cria uma figura com 1 linha e 2 eixos (subplots) lado a lado; tamanho total de 16×4 polegadas.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,4))\n",
    "\n",
    "# Plota a curva de loss de treino (ignorando o primeiro ponto) no primeiro eixo.\n",
    "ax1.plot(loss_treino[1:], label='Train')\n",
    "# Plota a curva de loss de teste (ignorando o primeiro ponto) no primeiro eixo.\n",
    "ax1.plot(loss_test[1:], label='Test')\n",
    "# Define o título do gráfico do primeiro eixo.\n",
    "ax1.set_title('Model Convergence - Loss')\n",
    "# Rótulo do eixo X do primeiro gráfico (épocas).\n",
    "ax1.set_xlabel('epochs')\n",
    "# Rótulo do eixo Y do primeiro gráfico (loss).\n",
    "ax1.set_ylabel('Loss')\n",
    "# Exibe a legenda para distinguir as curvas de treino e teste no primeiro eixo.\n",
    "ax1.legend()\n",
    "\n",
    "# Plota a curva de acurácia de treino no segundo eixo.\n",
    "ax2.plot(acc_treino, label='Train')\n",
    "# Plota a curva de acurácia de teste no segundo eixo.\n",
    "ax2.plot(acc_test, label='Test')\n",
    "# Define o título do gráfico do segundo eixo.\n",
    "ax2.set_title('Model Convergence - Accuracy')\n",
    "# Rótulo do eixo X do segundo gráfico (épocas).\n",
    "ax2.set_xlabel('epochs')\n",
    "# Rótulo do eixo Y do segundo gráfico (acurácia).\n",
    "ax2.set_ylabel('Accuracy')\n",
    "# Exibe a legenda para distinguir as curvas de treino e teste no segundo eixo.\n",
    "ax2.legend()\n",
    "# Mostra a figura com os dois gráficos lado a lado.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Dkx4uHTz-8l"
   },
   "source": [
    "## Usando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1605623359600,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gihu3QVmkuyR2Al5S_BxrjkrW8O_oUwd2ROuOwQerU=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "Rul7kSlY0Aui",
    "outputId": "9301be34-76f7-493f-8b40-d9f348cbbe26"
   },
   "outputs": [],
   "source": [
    "# Define uma função de inferência que recebe um nome (string) e imprime as 3 classes mais prováveis.\n",
    "def predict(nome):\n",
    "  # Coloca o modelo em modo de avaliação (desativa Dropout e usa BN com estatísticas fixas).\n",
    "  model.eval()\n",
    "\n",
    "  # Cria um tensor one-hot zerado com uma linha por caractere e uma coluna por símbolo do vocabulário.\n",
    "  tns = torch.zeros( len(nome), tam_dicionario )\n",
    "  # Percorre cada caractere do nome e marca a coluna correspondente no one-hot.\n",
    "  for k, letra in enumerate(nome):\n",
    "    # Busca o índice da letra no vocabulário; se não existir, retorna -1.\n",
    "    idx = caracteres_validos.find(letra)\n",
    "    # Só marca 1.0 se a letra for conhecida (idx >= 0); evita escrever na coluna -1 por engano.\n",
    "    if idx >= 0:                 # << evita o índice -1\n",
    "        tns[k, idx] = 1.0\n",
    "    # Caso contrário, mantém a linha toda zero (caractere ignorado).\n",
    "    # else: linha fica toda zero (caractere ignorado)\n",
    "  # Move o tensor de entrada para o dispositivo configurado (CPU/GPU).\n",
    "  tns = tns.to(args['device'])\n",
    "\n",
    "  # Forward: obtém as pontuações (aqui, log-probabilidades se o modelo usar LogSoftmax na saída).\n",
    "  saida = model(tns)\n",
    "  # Seleciona o top-3 ao longo da dimensão das classes (dim=1); retorna valores e índices.\n",
    "  topv, topi = saida.data.topk(3, 1, True)\n",
    "\n",
    "  # Imprime o nome consultado.\n",
    "  print(nome)\n",
    "  # Itera pelos pares (valor, índice) do top-3 para exibir a classe prevista.\n",
    "  # OBS: `index` é um tensor escalar; se necessário para indexação em listas, use `index.item()`.\n",
    "  for value, index in zip(topv[0], topi[0]):\n",
    "    # Mostra a pontuação (value) e a classe correspondente em `categorias`.\n",
    "    print('(%.2f) %s' % (value, categorias[index]))\n",
    "  # Linha em branco para separar chamadas.\n",
    "  print('\\n')\n",
    "\n",
    "# Exemplos de uso da função de predição com três nomes.\n",
    "predict('Merkel')\n",
    "predict('Hirobumi')\n",
    "predict('Suarez')\n",
    "predict('Ow-Gao')\n",
    "predict('De la mancha')\n",
    "predict('Lessa')\n",
    "predict('Leça')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo treinado em disco\n",
    "torch.save(model.state_dict(), 'rnn_gru_name_classifier.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM4D023QOGnkkQJXatAtmLz",
   "collapsed_sections": [],
   "name": "Classificação de Sequências-GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
